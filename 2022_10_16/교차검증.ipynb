{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5238a7d6",
   "metadata": {},
   "source": [
    "### 회귀\n",
    "\n",
    "#### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd376a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ba2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 수집\n",
    "x_data = np.array([\n",
    "    [2,1],\n",
    "    [3,2],\n",
    "    [3,4],\n",
    "    [5,5],\n",
    "    [7,5],\n",
    "    [2,5],\n",
    "    [8,9],\n",
    "    [9,10],\n",
    "    [6,12],\n",
    "    [9,2],\n",
    "    [6,10],\n",
    "    [2,4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56e27b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "#KFold 적용,데이터셋을 5개로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c118426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index: [ 3  4  5  6  7  8  9 10 11]\n",
      "test_index: [0 1 2]\n",
      "train_index: [ 0  1  2  6  7  8  9 10 11]\n",
      "test_index: [3 4 5]\n",
      "train_index: [ 0  1  2  3  4  5  8  9 10 11]\n",
      "test_index: [6 7]\n",
      "train_index: [ 0  1  2  3  4  5  6  7 10 11]\n",
      "test_index: [8 9]\n",
      "train_index: [0 1 2 3 4 5 6 7 8 9]\n",
      "test_index: [10 11]\n"
     ]
    }
   ],
   "source": [
    "#교차검증의 train 데이터셋과 test 데이터셋을 확인하기 위한 반복문\n",
    "for train_index,test_index in kf.split(x_data):\n",
    "    print('train_index:',train_index)\n",
    "    print('test_index:',test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99903e3c",
   "metadata": {},
   "source": [
    "### K-Fold 교차검증 -> 보통 회귀 문제에 사용됨\n",
    "- 학습데이터와 테스트 데이터를 k개의 세트로 나누어 검증하는 방법\n",
    "- 데이터셋이 굉장히 적을 때 훈련 데이터를 어떻게든 최대한 늘려보려고 사용하는 것\n",
    "- 여러개의 훈련테스트 짝으로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7144b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b47740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 수집\n",
    "x_data = np.array([\n",
    "    [2,1],\n",
    "    [3,2],\n",
    "    [3,4],\n",
    "    [5,5],\n",
    "    [7,5],\n",
    "    [2,5],\n",
    "    [8,9],\n",
    "    [9,10],\n",
    "    [6,12],\n",
    "    [9,2],\n",
    "    [6,10],\n",
    "    [2,4]\n",
    "])\n",
    "\n",
    "y_data = np.array([3,5,7,10,12,7,13,13,12,13,12,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de644ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50aa29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#교차검증의 정확도를 보기 위한 for문\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "kf = KFold(n_splits=5) #데이터 5개로 쪼갬\n",
    "\n",
    "for train_index,test_index in kf.split(x_data):\n",
    "    x_train = np.array(x_data)[train_index]\n",
    "    y_train = np.array(y_data)[train_index]\n",
    "    x_test = np.array(x_data)[test_index]\n",
    "    y_test = np.array(y_data)[test_index]\n",
    "    \n",
    "    lr= LinearRegression() #모델선정\n",
    "    lr.fit(x_train,y_train) #모델 학습\n",
    "    #훈련데이터\n",
    "    score = lr.score(x_train,y_train)\n",
    "    train_scores.append(score) #r2_score\n",
    "    \n",
    "    #평가데이터\n",
    "    score_test = lr.score(x_test,y_test)\n",
    "    test_scores.append(score_test) #r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ecfa23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9522707858769932,\n",
       " 0.9469593697441799,\n",
       " 0.9446524178499608,\n",
       " 0.9232432525564045,\n",
       " 0.9166499001004778]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a271457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1475590101753324,\n",
       " 0.56847222331606,\n",
       " 0.0,\n",
       " -11.7747639790487,\n",
       " 0.9602035173350366]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606903fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9367551452256032\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_scores).mean())\n",
    "#train데이터의 r2_score 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8932d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.278729449714587\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_scores).mean())\n",
    "#test 데이터의 r2_score 평균\n",
    "# -값나옴, 예측이 잘 안됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02595b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_data,y_data)\n",
    "x_test=np.array([\n",
    "    [4,6]\n",
    "])\n",
    "y_predict = lr.predict(x_test)\n",
    "#새로운 데이터 넣고 그 데이터에 대한 예측값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a65440d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.27950438])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51649688",
   "metadata": {},
   "source": [
    "### 계층별 K-겹 교차검증(Stratified K-Fold Cross Validation)\n",
    "- 분류모델에 적용\n",
    "- k-겹 교차검증은 k-fold가 원본 데이터 집합의 레이블 분포를 학습 및 검증 데이터 세트에 제대로 분배하지 못하는 문제가 있는데, 레이블에 속성값의 개수를 골고루 넣어줌\n",
    "\n",
    "- 계층적 교차 검증은 K-fold의 향상된 버전입니다. 이 방법은 폴드를 나눌 때 각 폴드간의 클래스 비율을 전체 훈련 세트의 클래스 비율과 일치하게 나눕니다. 이것은 결과적으로 모델이 좀더 나은 편향과 분산을 가지게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "326e12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdceb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "#데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fda6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "#모델선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee49ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5,random_state=3,shuffle=True)\n",
    "#계층별 K-fold 교차검증, 5개의 데이터로 데이터 나눔, 3번 시드\n",
    "#shuffle = True :데이터를 무작위로 섞음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "589b9dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf78b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "521cd974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 교차 검증 정확도: 1.0 \n",
      " 학습 데이터 크기: 120 \n",
      " 검증 데이터 크기 : 30\n",
      "2번째 교차 검증 정확도: 0.9667 \n",
      " 학습 데이터 크기: 120 \n",
      " 검증 데이터 크기 : 30\n",
      "3번째 교차 검증 정확도: 0.9 \n",
      " 학습 데이터 크기: 120 \n",
      " 검증 데이터 크기 : 30\n",
      "4번째 교차 검증 정확도: 1.0 \n",
      " 학습 데이터 크기: 120 \n",
      " 검증 데이터 크기 : 30\n",
      "5번째 교차 검증 정확도: 0.9667 \n",
      " 학습 데이터 크기: 120 \n",
      " 검증 데이터 크기 : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#교차검증의 정확도를 확인하기 위한 반복문 작성 \n",
    "idx_iter = 0 #반복수\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index,test_index in skf.split(x,y):\n",
    "    x_train,x_test = x[train_index],x[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    \n",
    "    #모델 학습(모델 계속 선정하면 오류날수도 있어서 위에 코드를 사용)\n",
    "    lr.fit(x_train,y_train) \n",
    "    \n",
    "    pred = lr.predict(x_test) #예측값 산출\n",
    "    \n",
    "    idx_iter += 1 #반복수 1 추가\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    #np.round(data, n) = 데이터를 소수 n번째저라까지 나오게 반올림\n",
    "    train_size = x_train.shape[0] #x_train의 행의 개수\n",
    "    test_size = x_test.shape[0] #x_test의 행의 개수\n",
    "    \n",
    "    print('{0}번째 교차 검증 정확도: {1} \\n 학습 데이터 크기: {2} \\n 검증 데이터 크기 : {3}'.format(idx_iter,\n",
    "                                                                             accuracy,\n",
    "                                                                             train_size,\n",
    "                                                                             test_size))\n",
    "    #.format()을 쓸때 괄호안에 먼저 나온것부터 {0}번 중괄호에 들어가는 식\n",
    "    # 들어가는 순서\n",
    "    \n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd4a48f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 : [1.     0.9667 0.9    1.     0.9667]\n",
      "평균 검증 정확도 : 0.96668\n"
     ]
    }
   ],
   "source": [
    "print('교차 검증별 정확도 :',np.round(cv_accuracy,4))\n",
    "print('평균 검증 정확도 :',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dee7e6",
   "metadata": {},
   "source": [
    "<교차 검증의 장점>\n",
    "1. test set에 데이터가 최소 한 번씩 들어가기 때문에 모델이 더 잘 일반화 됨\n",
    "2. 분할을 한 번 했을 때보다 데이터를 더 효과적으로 사용해서 더 정확한 모델을 만들 수 있다\n",
    "\n",
    "<교차 검증의 단점>\n",
    "1. 연산 비용이 늘어남(k개의 모델을 만들어야 하므로 데이터를 한 번 나눴을 때에 비해서 느리다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d11a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
